{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ae7bc89ae06977",
   "metadata": {},
   "source": [
    "# Demo: How to Modify Models Using GRADIEND\n",
    "\n",
    "1. Select a model to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84abf498239142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, pipeline, logging\n",
    "\n",
    "# Suppress warnings from Hugging Face transformers library\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiend.combined_models.test_combined_ae import CombinedEncoderDecoder\n",
    "from gradiend.model import ModelWithGradiend\n",
    "from hydra import initialize, compose\n",
    "from gradiend.training.trainer import train\n",
    "\n",
    "with initialize(config_path=\"conf\", version_base=None):  # adjust path relative to notebook\n",
    "        # Step 2: Compose the configuration with overrides\n",
    "        cfg = compose(\n",
    "            config_name=\"config\",\n",
    "            overrides=[\n",
    "                \"mode.name=gradiend\",\n",
    "                \"pairing=MFN_UL\",\n",
    "                \"num_runs=1\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        MF = \"results/experiments/gradiend/MF/1e-05/bert-base-german-cased/0\"\n",
    "        MN = \"results/experiments/gradiend/MN/1e-05/bert-base-german-cased/0\"\n",
    "        FN = \"results/experiments/gradiend/FN/1e-5/bert-base-german-cased/0\"\n",
    "\n",
    "        MF_model = ModelWithGradiend.from_pretrained(MF)\n",
    "        base_model = MF_model.base_model\n",
    "        tokenizer = MF_model.tokenizer\n",
    "        MN_model = ModelWithGradiend.from_pretrained(MN)\n",
    "        FN_model = ModelWithGradiend.from_pretrained(FN)\n",
    "\n",
    "        combined_ae = CombinedEncoderDecoder([MF_model, MN_model, FN_model])\n",
    "        model_with_gradiend = ModelWithGradiend(base_model, combined_ae, tokenizer)\n",
    "        model_config = cfg.mode.model_config \n",
    "        config = cfg.pairing\n",
    "\n",
    "        train(model_with_gradiend, config=config, **model_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e038fde731b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:35:01.732651Z",
     "start_time": "2025-01-30T18:35:01.729221Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "model = 'bert-base-cased'\n",
    "distilbert_de = 'distilbert-base-german-cased'\n",
    "bert_de = 'bert-base-german-cased'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a009ee09d10566",
   "metadata": {},
   "source": [
    "2. Train the GRADIEND model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002899e0cd238bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiend.training.gradiend_training import train\n",
    "\n",
    "# you may override some default behavior of gradiend.training.trainer.train() with the model_config\n",
    "model_config = {\n",
    "    'eval_max_size': 0.1, # use all of the validation data\n",
    "    'epochs': 1,\n",
    "    'lr': 1e-4,\n",
    "}\n",
    "\n",
    "gradiend_model_dir = train(bert_de,config, model_config, multi_task=False, n=1, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803af899d63e874",
   "metadata": {},
   "source": [
    "3. [Optional]: Analyze the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31c64b7cf14a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:35:21.769015Z",
     "start_time": "2025-01-30T18:35:03.837024Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from gradiend.evaluation.analyze_encoder import analyze_models\n",
    "from gradiend.export.encoder_stats import print_encoder_stats\n",
    "from gradiend.export.encoder_plot import plot\n",
    "\n",
    "config = yaml.safe_load(open(\"config.yml\"))['M_F_N_leipzig']\n",
    "gradiend_model_dir = \"results/models/gradiend\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyze_models(gradiend_model_dir, config=config, multi_task=False, shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_encoder_stats(gradiend_model_dir, config=config)\n",
    "\n",
    "# plot the encoded values distribution across different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(config, gradiend_model_dir, multi_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradiend_model_dir = \"gradiend/results/experiments/gradiend/multi_task/gradient/latent_2/1e-05/batch_16_nom_only/epoch_3/bert-base-german-cased/0_epoch_3\"\n",
    "config = yaml.safe_load(open(\"config.yml\"))['DAS_PRON']\n",
    "\n",
    "plot(config, gradiend_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff004bbf94f063e",
   "metadata": {},
   "source": [
    "4. Analyze the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d1895899af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:52:37.123950Z",
     "start_time": "2025-01-30T16:47:45.448333Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.analyze_decoder import default_evaluation\n",
    "default_evaluation(gradiend_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fff41b2161e5f0",
   "metadata": {},
   "source": [
    "5. Create modified models based on the base models by selecting parameters based on the analysis and the BPI, FPI, and MPI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62978d082d3a381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:40:56.208283Z",
     "start_time": "2025-01-30T18:40:42.609154Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.select_models import select\n",
    "result = select(gradiend_model_dir, force=False, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239d390e3c028a7",
   "metadata": {},
   "source": [
    "6. Load the modified models and do something with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4baee2b749a006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T17:09:03.377149Z",
     "start_time": "2025-01-30T17:09:02.194546Z"
    }
   },
   "outputs": [],
   "source": [
    "for suffix in ['N', 'F', 'M']:\n",
    "    model_name = f'results/changed_models/{model}-{suffix}'\n",
    "    print(f'Loading model {model_name}')\n",
    "    modified_model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # do something with the model\n",
    "    # ...\n",
    "    \n",
    "    # Example: Use the pipeline to predict the masked word    \n",
    "    fill_mask = pipeline(\"fill-mask\", model=model_name, tokenizer=model_name)\n",
    "    text = 'The man worked as a [MASK].'\n",
    "    result = fill_mask(text)\n",
    "    predicted = result[0]['token_str']\n",
    "    predicted_prob = result[0]['score']\n",
    "    print(f'Predicted for {suffix}: {predicted} ({predicted_prob})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740aa238cec6dfd",
   "metadata": {},
   "source": [
    "7. [Optional]: Evaluate the modified models on a simple masking task to evaluate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97979d62a69e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:23:11.105096Z",
     "start_time": "2025-01-30T18:20:59.038708Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.analyze_decoder import evaluate_gender_prediction_for_models\n",
    "from gradiend.export.gender_predictions import plot_all\n",
    "\n",
    "for targets in [('man', 'woman'), ('woman', 'man')]:\n",
    "    evaluate_gender_prediction_for_models(model, target_words=targets)\n",
    "    suffix = '_'.join(targets)\n",
    "    plot_all(f'results/gender_prediction/{model}.csv', suffix=suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39b4279bed6af8",
   "metadata": {},
   "source": [
    "8. [Optional]: Generate some example predictions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510112a9839f23d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T15:01:40.690487Z",
     "start_time": "2025-01-30T15:01:29.668910Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.export.example_predictions import run_for_model\n",
    "run_for_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradiend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
