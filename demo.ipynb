{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ae7bc89ae06977",
   "metadata": {},
   "source": [
    "# Demo: How to Modify Models Using GRADIEND\n",
    "\n",
    "1. Select a model to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f84abf498239142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, pipeline, logging\n",
    "\n",
    "# Suppress warnings from Hugging Face transformers library\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e038fde731b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:35:01.732651Z",
     "start_time": "2025-01-30T18:35:01.729221Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "model = 'bert-base-cased'\n",
    "distilbert_de = 'distilbert-base-german-cased'\n",
    "bert_de = 'bert-base-german-cased'\n",
    "\n",
    "config = yaml.safe_load(open(\"config.yml\"))['M_F_N_leipzig']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a009ee09d10566",
   "metadata": {},
   "source": [
    "2. Train the GRADIEND model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002899e0cd238bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradiend.training.gradiend_training import train\n",
    "\n",
    "# you may override some default behavior of gradiend.training.trainer.train() with the model_config\n",
    "model_config = {\n",
    "    'eval_max_size': 0.1, # use all of the validation data\n",
    "    'epochs': 1,\n",
    "    'lr': 1e-4,\n",
    "}\n",
    "\n",
    "gradiend_model_dir = train(bert_de,config, model_config, multi_task=False, n=1, dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803af899d63e874",
   "metadata": {},
   "source": [
    "3. [Optional]: Analyze the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c31c64b7cf14a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:35:21.769015Z",
     "start_time": "2025-01-30T18:35:03.837024Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from gradiend.evaluation.analyze_encoder import analyze_models\n",
    "from gradiend.export.encoder_stats import print_encoder_stats\n",
    "from gradiend.export.encoder_plot import plot\n",
    "\n",
    "config = yaml.safe_load(open(\"config.yml\"))['M_F_N_leipzig']\n",
    "gradiend_model_dir = \"results/models/gradiend\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9e46f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plot_name': 'MFN_leipzig', 'palette': {'M': 'blue', 'F': 'purple', 'N': 'yellow'}, 'categories': {'M': {'labels': ['AM', '_AM'], 'articles': ['den'], 'codes': [0, 1, 2, 3], 'encoding': -1}, 'F': {'labels': ['AF', '_AF'], 'articles': ['die'], 'codes': [4, 5, 6, 7], 'encoding': 1}, 'N': {'labels': ['AN', '_AN'], 'articles': ['das'], 'codes': [8, 9, 10, 11], 'encoding': 0}}, 'combinations': ['AM_mfn', 'AF_mfn', 'AN_mfn'], 'articles': ['die', 'das', 'den'], 'default_predictions': ['die', 'das', 'den', 'most_likely_token', 'label'], 'token_to_ignore': ['der', 'die', 'das', 'den', 'der', 'Den', 'DEN', 'Der', 'Die', 'Das', 'DER', 'DIE', 'DAS'], 'NM': {'mask': '[NM]', 'inverse': 'die', 'code': 0, 'encoding': -1}, '_NM': {'mask': '[NM]', 'inverse': 'das', 'code': 0, 'encoding': -1}, 'AM': {'mask': '[AM]', 'inverse': 'die', 'code': 2, 'encoding': -1}, '_AM': {'mask': '[AM]', 'inverse': 'das', 'code': 2, 'encoding': -1}, 'NF': {'mask': '[NF]', 'inverse': 'der', 'code': 4, 'encoding': 1}, '_NF': {'mask': '[NF]', 'inverse': 'das', 'code': 4, 'encoding': 1}, 'AF': {'mask': '[AF]', 'inverse': 'den', 'code': 6, 'encoding': 1}, '_AF': {'mask': '[AF]', 'inverse': 'das', 'code': 6, 'encoding': 1}, 'NN': {'mask': '[NN]', 'inverse': 'der', 'code': 8, 'encoding': 0}, '_NN': {'mask': '[NN]', 'inverse': 'die', 'code': 8, 'encoding': 0}, 'AN': {'mask': '[AN]', 'inverse': 'die', 'code': 10, 'encoding': 0}, '_AN': {'mask': '[AN]', 'inverse': 'den', 'code': 10, 'encoding': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyze_models(gradiend_model_dir, config=config, multi_task=False, shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_encoder_stats(gradiend_model_dir, config=config)\n",
    "\n",
    "# plot the encoded values distribution across different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(config, gradiend_model_dir, multi_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradiend_model_dir = \"gradiend/results/experiments/gradiend/multi_task/gradient/latent_2/1e-05/batch_16_nom_only/epoch_3/bert-base-german-cased/0_epoch_3\"\n",
    "config = yaml.safe_load(open(\"config.yml\"))['DAS_PRON']\n",
    "\n",
    "plot(config, gradiend_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff004bbf94f063e",
   "metadata": {},
   "source": [
    "4. Analyze the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d1895899af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T16:52:37.123950Z",
     "start_time": "2025-01-30T16:47:45.448333Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.analyze_decoder import default_evaluation\n",
    "default_evaluation(gradiend_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fff41b2161e5f0",
   "metadata": {},
   "source": [
    "5. Create modified models based on the base models by selecting parameters based on the analysis and the BPI, FPI, and MPI metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62978d082d3a381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:40:56.208283Z",
     "start_time": "2025-01-30T18:40:42.609154Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.select_models import select\n",
    "result = select(gradiend_model_dir, force=False, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239d390e3c028a7",
   "metadata": {},
   "source": [
    "6. Load the modified models and do something with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4baee2b749a006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T17:09:03.377149Z",
     "start_time": "2025-01-30T17:09:02.194546Z"
    }
   },
   "outputs": [],
   "source": [
    "for suffix in ['N', 'F', 'M']:\n",
    "    model_name = f'results/changed_models/{model}-{suffix}'\n",
    "    print(f'Loading model {model_name}')\n",
    "    modified_model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # do something with the model\n",
    "    # ...\n",
    "    \n",
    "    # Example: Use the pipeline to predict the masked word    \n",
    "    fill_mask = pipeline(\"fill-mask\", model=model_name, tokenizer=model_name)\n",
    "    text = 'The man worked as a [MASK].'\n",
    "    result = fill_mask(text)\n",
    "    predicted = result[0]['token_str']\n",
    "    predicted_prob = result[0]['score']\n",
    "    print(f'Predicted for {suffix}: {predicted} ({predicted_prob})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740aa238cec6dfd",
   "metadata": {},
   "source": [
    "7. [Optional]: Evaluate the modified models on a simple masking task to evaluate overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97979d62a69e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:23:11.105096Z",
     "start_time": "2025-01-30T18:20:59.038708Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.evaluation.analyze_decoder import evaluate_gender_prediction_for_models\n",
    "from gradiend.export.gender_predictions import plot_all\n",
    "\n",
    "for targets in [('man', 'woman'), ('woman', 'man')]:\n",
    "    evaluate_gender_prediction_for_models(model, target_words=targets)\n",
    "    suffix = '_'.join(targets)\n",
    "    plot_all(f'results/gender_prediction/{model}.csv', suffix=suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39b4279bed6af8",
   "metadata": {},
   "source": [
    "8. [Optional]: Generate some example predictions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510112a9839f23d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T15:01:40.690487Z",
     "start_time": "2025-01-30T15:01:29.668910Z"
    }
   },
   "outputs": [],
   "source": [
    "from gradiend.export.example_predictions import run_for_model\n",
    "run_for_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradiend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
